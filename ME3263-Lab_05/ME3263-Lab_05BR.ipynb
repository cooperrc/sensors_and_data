{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Laboratory 5 - Background and Resources\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this lab, you will apply many of the skills you have learned over the previous weeks. With your knowledge of FFT, linear regression, \n",
    "and FEM modal analysis, you will develop and implement a method to measure the mass of an object. Your measurement device will be your\n",
    "cantilevered beam, and you will observe the changes in its natural frequencies that result from attaching the object to various pre-\n",
    "defined points on the beam (Figure 1). From these frequency changes, you will deduce the unknown mass.\n",
    "\n",
    "![Mass measurement cantilever](./contest_diagram.png)\n",
    "\n",
    "*Figure 1: Diagram of cantilever with unknown mass in position 2 out of 3 total\n",
    "positions. The red area indicates the placement of an accelerometer.*\n",
    "\n",
    "An accelerometer will provide the data describing the motion of the beam. This type of sensor employs a micron-scale spring-mass \n",
    "system (Figure 2). When under acceleration, this mass moves relative to a set of fixed plates, inducing a change in capacitance. This\n",
    "change is proportional to accleration.\n",
    "\n",
    "![accelerometer](./accelerometer.png)\n",
    "\n",
    "*Figure 2: Micron-scale sensor used in accelerometers. Under acceleration, the change in capacitances CS1 and CS2 will be\n",
    "proportional to the acceleration.*\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. What affects natural frequencies, and how do we measure them?\n",
    "\n",
    "In Lab 3, we saw that the natural frequencies of a cantilever beam can be described using Euler-Bernoulli beam theory:\n",
    "\n",
    "$\\omega_i=\\beta_i^2\\sqrt{\\frac{EI}{\\bar{m}L^4}}$ (1)\n",
    "\n",
    "where the $i^{th}$ natural frequency, $\\omega_i$ is given in rad/s, $\\beta_1=1.875104$, $\\beta_2=4.694091$, $\\beta_3=7.854757$, $\\bar{m}$ is the mass per unit length, $E$ is Young's modulus, and $I$ is the second moment of area of the beam.\n",
    "\n",
    "There are four factors that affect the natural frequency: stiffness ($E$), mass ($\\bar{m}$), second moment of area of cross-section ($I=bt^3/12$ for rectangular cross-section of $b\\times t$), and length $L$. We can see from Equation 1 that _adding mass_ or _increasing length_ will lower the natural frequencies and _increasing stiffness_ or _increasing cross-sectional area_ will raise them.\n",
    "\n",
    "The **accelerometer** shown in Figure 2 above will provide an _acceleration vs. time_ curve in response to an impulse applied to the beam. Thanks to the properties of derivatives of harmonic functions, the frequencies present in this _acceleration_ data will be the same as the frequencies that describe the beam's _displacement_. In other words - performing a **fast Fourier transform** on the acceleration signal will reveal the natural frequencies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. How can we predict the effects of added mass?\n",
    "\n",
    "In Lab 4, we used Ansys to perform an **FEM modal analysis** of our beam. It is straightforward to add a so-called \"**point mass**\" to our beam model, with a location and magnitude of our choosing. We can re-run the analysis to see the changes in natural frequency due to this added mass. By **varying the location and/or magnitude of the mass**, we can come up with a picture of the relationship between point mass characteristics and change in the natural frequencies of the beam.\n",
    "\n",
    "In Lab 2, we used **regression analysis** to discover the relationship between beam curvataure and applied moment. The same can be done here. For example, we could find a regression expressing mass as a function of change in frequency.\n",
    "\n",
    "It could be useful to note that **curve_fit** from the **scipy.optimize** module can accept a multidimensional array as independent variables. In other words, we can fit **two or more inputs** to one output. Below, we define a function for use with `curve_fit` that uses two independent variables (x and y). This is easily extensible to more than two independent variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import curve_fit   #import the appropriate modules\n",
    "\n",
    "def func(X, a, b):                #define our function input (X) and coefficients (a,b),      \n",
    "    x,y = X                       #unpack array X into two variables,     \n",
    "    return a*x + b*y              #and define the form of the function to fit      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the above code block will not do much - we haven't supplied any data, nor have we called `curve_fit`.\n",
    "\n",
    "The data for each independent variable will be a column of an array. They must be of the same length, and must both be the same length as the data array for the _dependent_ variable you wish to fit the curve to. The order matters - the $i^{th}$ elements of the independent variables must correspond to the $i^{th}$ element of the dependent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here, OutputData, InputData1, and InputData2 are presumably imported from some data source\n",
    "\n",
    "dependent_variable = OutputData                    \n",
    "independent_variables = (InputData1,InputData2)  #This creates a two-column array of our two independent variables\n",
    "\n",
    "#Using curve_fit to find coefficients a and b of our function defined above. \n",
    "#It will also return pcov, the covariance matrix\n",
    "coeff, pcov = curve_fit(func, independent_variables, dependent_variable)  \n",
    "a = coeff[0]\n",
    "b = coeff[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, the above code block is not executable - we have not supplied `OutputData`,`IndputData1`, or `InputData2`. It should, however, illustrate the procedure for this usage of `curve_fit`.\n",
    "\n",
    "It will be possible, with an appropriate regression, to express the **unknown mass as a function of natural frequencies**. The example we looked at in class was very similar - developing a regression for measuring the thickness of a gold coating on a micro-scale silicon cantilever."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. How certain can we be of our prediction?\n",
    "\n",
    "In Lab 2, we used propagation of error analysis based on sensitivity indices to determine the contribution of our measurement uncertainties to the overall uncertainty in our estimate of Young's modulus. For this lab, our uncertainties do not result from measurements. Instead, they primarily result from the \"goodness\" of our regression model.\n",
    "\n",
    "### Standard error of the fit\n",
    "\n",
    "In Lecture 7, we discussed a **standard deviation** based on the deviation of each data point predicted by the fit. It is called the _standard error of the fit_, and can be expressed as:\n",
    "\n",
    "$S_{yx} = \\sqrt{\\frac{\\sum_{i=1}^N(y_i - y_{c,i})^2}{\\nu}}$   (2)\n",
    "\n",
    "where $N$ is the number of data points, $y_i$ is the measured (in our case found by simulation) value, $y_{c,i}$ is the value of the data point calculated by the fit, and $\\nu$ is the degrees of freedom of the fit. \n",
    "\n",
    "$\\nu = N - (m + 1)$  (3)\n",
    "\n",
    "where $m$ is the number of coefficients in the regression.\n",
    "\n",
    "This standard deviation, like any other standard deviation, can be used with **Student's t-distribution** to produce a **confidence interval** for the values calculated using your regression.\n",
    "\n",
    "$y = y_c \\pm t_{\\nu,P}S_{yx}$       $(P\\%)$  (4)\n",
    "\n",
    "where $y_c$ is the calculated value and $t_{\\nu,P}$ is the t-value corresponding to the degrees of freedom $\\nu$ and desired confidence level $P$.\n",
    "\n",
    "### The covariance matrix\n",
    "\n",
    "Alternatively, information about the **variance of the regression parameters** is given by the output of `curve_fit`. This information is in the form of the \"covariance matrix\", and is called `pcov` in the above example code and in the example code for Lab 2. The diagonal elements of this matrix are the variances of the regression coefficients, in order. Their square roots provide a one-standard-deviation estimate of the **uncertainty in the coefficients**. Continuing the above example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_err = np.sqrt(pcov[0,0])\n",
    "b_err = np.sqrt(pcov[1,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the example function of $x$ and $y$ shown in the above regression,\n",
    "\n",
    "$f(x,y) = ax+by$   (5)\n",
    "\n",
    "The uncertainties in $a$ and $b$ (i.e, $u_a$ and $u_b$) are `a_err` and `b_err`, respectively. We can use sensitivity indices to estimate the uncertainty in $f$ due to the uncertainties $u_a$ and $u_b$:\n",
    "\n",
    "$u_f = \\sqrt{(\\theta_au_a)^2+(\\theta_bu_b)^2}$  (6)\n",
    "\n",
    "This prediction, however, is not at the common 95% confidence level. Rather, it is a prediction of one standard deviation error in the calculated value. It is a valid estimate of uncertainty, as long as the reader is made aware of what the number indicates."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
